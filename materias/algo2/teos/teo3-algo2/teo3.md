---
layout: page
title: Te√≥rica 3
permalink: /materias/algo2/teo3/
---
# An√°lisis de complejidad

Para resolver problemas, queremos que nuestros algoritmos:

- **Funcionen correctamente**
    - modelen bien el problema
    - los algoritmos terminen
    - devuelvan el resultado correcto
- **Sean eficientes** en t√©rminos del consumo de recursos.

**¬øCu√°les son los recursos que se consumen?**

- Tiempo de ejecuci√≥n
- Espacio en memoria
- Cantidad de procesadores
- Utilizaci√≥n de la red de comunicaciones

Otros criterios (que no vamos a tener en cuenta):

- Claridad de la soluci√≥n
- Facilidad de codificaci√≥n

En general no se pueden optimizar todos al mismo tiempo, hay que **balancear** y darle m√°s importancia a algunos recursos que a otros.

Nosotros vamos a priorizar **el tiempo y el espacio**.  Principalmente el tiempo. ¬øPor qu√©? Porque el tiempo no se recupera.

**¬øC√≥mo se puede medir la comlpejidad de los algoritmos?**

- Forma emp√≠rica/experimental (medir segundos, ticks de clock, etc.)
- Forma te√≥rica

Como la forma emp√≠rica puede cambiar mucho seg√∫n el contexto en el que ejecutemos, la capacidad de la computadora, etc., **vamos a usar la te√≥rica** porque permite tener resultados mucho m√°s generales.

### Vemos el ejemplo de b√∫squeda secuencial en un array.

¬øDepende de cu√°l buscamos? ¬øDepende de la cantidad de elementos del array? 

### An√°lisis Te√≥rico

Ventajas del enfoque te√≥rico:

- El an√°lisis se puede a ser **a priori**, antes de codear.
- Vale para **todas las instancias** del problema.
- Es **independiente del lenguaje de programaci√≥n.**
- Es **independiente de la m√°quina**.
- Es **independiente de la pericia del programador**.

1. Se basa en un **modelo de m√°quina** consensuado.
2. En funci√≥n del **tama√±o del input.**
3. Para distintos **tipos de input.**
4. **An√°lisis asint√≥tico.**

---

### **Modelo de c√≥mputo**

- Queremos una medida universal v√°lida para distintas implementaciones del algoritmo.
- La idea es tener un banco de pruebas te√≥rico/virtual.
- Definimos una m√°quina ideal
- Medida del tiempo: n√∫mero de pasos u operaciones que se ejecutan en esa m√°quia para determinado input.
- Medida del espacio: n√∫mero de posiciones de memoria que se utilizan en esa m√°quina para determinado input.

### **Operaciones Elementales.**

- t(l) va a ser la funci√≥n que mida el n√∫mero de operaciones elementales para la instancia l.
- Las OE ser√°n aquellas que el procesador realiza en tiempo acotado por una constante (no depende del tama√±o de entrada).
- OEs: operaciones aritm√©ticas b√°sicas, comparaciones l√≥gicas, transferencias de control, asignaciones a variables de tipos b√°sicos, etc.

**C√°lculo de OE**

- Vamos a considerar que el tiempo de una OE es 1.
- El tiempo de ejecuci√≥n de una secuencia consecutiva de instrucciones se calcula sumando los tiempos de ejecuci√≥n de cada instrucci√≥n.

ejemplo:

```c
buscar: int x, array A -> int 
l <- 1                                                   1
encontr√© <- falso                                        1
mientras ¬¨encontr√©:                                      2*4  
	si A[l] = x entonces encontr√© <- verdadero             2*3 + 3   
	l <- l+1                                               3*4                              
print(l-1)                                               1       

Buscar(5, [2, 6, 3, 5, 8])
aprox 30 Operaciones Elementales.

Buscar(6, [2, 6, 3, 5, 8]) un poco menos
Buscar(8, [2, 6, 3, 5, 8]) un poco m√°s

¬øY si el arreglo en vez de tener 5 elementos tiene 10? 
‚Üí Va a tener m√°s operaciones elementales.
```

**Vamos a empezar a pensar la complejidad en funci√≥n del tama√±o del input.**

Reglas generales del c√°lculo de Operaciones Elementales:

- Si tenemos un `if C then S1 else S2` va a tardar T = T(comparaci√≥n) + m√°x{T(S1), T(S2)}
- Si tenemos un `while C do S` va a ser T = T(C) + nro_iteraciones*(T(S)+T(C)).

<aside>
‚ö†Ô∏è T(S) y T(C) pueden ir variando en cada iteraci√≥n, y si queremos analizar **bien** la complejidad va a haber que tenerlo en cuenta.

</aside>

- Llamada a una funci√≥n `F(p1, p2, .., pn)`, vamos a medir 1 por la llamada, luego por la evaluaci√≥n de los par√°metros y luego por el T de la funci√≥n. ‚Üí T= 1 + T(p1) + T(p2) + ... + T(pn) + T(F).

---

### Tama√±o del input

¬øPor qu√© se mide la complejidad en funci√≥n del tama√±o de la entrada?

- Queremos complejidad **relativa, no absoluta.**
- Es una medida general. Queremos predecir, no medir para una instancia particular.
- M√°s abstracto que pensarlo para cada input. Podr√≠a haber infinitos inputs, imposible de calcular eso.

**T(n): complejidad temporal para una entrada de tama√±o n.**

**S(n): complejidad espacial para una entrada de tama√±o n.**

Como puede haber 2 inputs del mismo tama√±o que sean distintos, vamos a tener que ser un poco m√°s espec√≠ficos. Por ejemplo: no es lo mismo trabajar el arreglo [1, 1, 2, 1, 0] que el [99999, 151895, 29115025, 942015, 1029401]. Es m√°s probable que si tenemos que operar con los elementos de el segundo arreglo tardemos m√°s.

Entonces, se suelen estudiar **tres casos** para un mismo algoritmo:

1. An√°lisis del **peor caso**
2. An√°lisis del **caso medio**
3. An√°lisis del **mejor caso**

<aside>
üö® El que m√°s vamos a usar va a ser el **an√°lisis de caso peor,** porque nos da **garant√≠as** sobre nuestro algoritmo. O sea podemos asegurar que va a tener esa complejidad o una menor.

</aside>

1. **An√°lisis del peor caso**
    
    $T_{peor}{(n)}$  es el tiempo de ejecuci√≥n del algoritmo sobre la instancia de tama√±o n que implica mayor tiempo de ejecuci√≥n.
    
    Por ejemplo, para b√∫squeda lineal en un arreglo, el peor caso es n, que es cuando el elemento est√° al final del arreglo.
    
2. **An√°lisis del mejor caso**
    
    Indica el tiempo de ejecuci√≥n sobre la instancia m√°s r√°pida entre los inputs de tama√±o n. No es muy utilizada.
    
3. **An√°lisis del caso medio/promedio**
    
    Corresponde al tiempo "**promedio".** O sea, al tiempo "**esperado"** sobre instancias "**t√≠picas".**
    
    Se define como la esperanza matem√°tica de la variable aleatoria definida por todas las posibles ejecuciones para un input del tama√±o dado, con las probabilidades de que estas ocurran para esa entrada.
    
    $T_{prom}{(n)} = \sum_{instancias\;l\;tq\;|l|=n}{P(l)*t(l)}$. 
    
    Es una medida de gran utilidad, **pero...** debemos conocer la distribuci√≥n estad√≠stica del input, para poder hacer hip√≥tesis realistas sobre lo que va a ingresar.
    
    Adem√°s, si tenemos un algoritmo que tarda 1 o 100 pasos no sirve dar el tiempo promedio (50) porque claramente nunca va a tardar eso.
    

Ejemplo b√∫squeda secuencial:

- $T_{peor}{(n)\;\; = \;8 + 5(n-1)}.$   Cuando el elemento est√° al final del arreglo.
- $T_{mejor}{(n) = 9}$.                          Cuando el elemento est√° al final del arreglo.
- $T_{prom}{(n) \;= 8 + 5(\frac{n}{2})}$.            Cuando est√° en la mitad.

Para ver la complejidad espacial, tenemos en cuenta el tama√±o del arreglo y el uso de las variables i, x y encontr√©:   $S(n) = n + 3$.

Si el arreglo estuviera ordenado ¬øcambiar√≠an los tiempos?. NO.

Pero... podemos cambiar el algoritmo por el de b√∫squeda binaria, tarda menos.

---

### Principio de invarianza

Dado un algoritmo y dos m√°quinas que tardan $T_{1}(n)$ y $T_{2}(n)$, existe una constante real $c > 0$ y un $n_{0} \in \N$  tales que $\forall \; n ‚â• n_{0}$ se verifica que: 

$$
T_{1}(n) ‚â§ c*T_{2}(n)
$$

O sea, dos ejecuciones distintas del mismo algoritmo s√≥lo difieren en un factor constante para entradas suficientemente grandes.

### An√°lisis asint√≥tico

Cuando el tama√±o de los datos es peque√±o no habr√° diferencias significativas en el uso de distintos algoritmos, pero para entradas m√°s grandes los costos pueden **variar de manera significativa.**

- **El orden** (logar√≠tmico, lineal, cuadr√°tico, exponencial) de la funci√≥n $T(n)$ que mide la complejidad de un algoritmo, es el que **expresa el comportamiento dominante** cuando el tama√±o de entrada es grande.
- **El comportamiento asint√≥tico** es el comportamiento para valores de entrada suficientemente grandes.

El objetivo del estudio de la complejidad es determinar el comportamiento asint√≥tico del algoritmo.

Medidas del comportamiento asint√≥tico:

- $O$ (O grande) cota superior.
- $\Omega$  (Omega) cota inferior.
- $\Theta$ (theta) orden exacto de la funci√≥n.

**Cota superior - Notaci√≥n $O$**

- Esta notaci√≥n sirve para representar la cota superior del tiempo de ejecuci√≥n de un algoritmo.
- La notaci√≥n $f \in O(g)$ significa que $f$ **no crece m√°s r√°pido que alguna funci√≥n proporcional a $g$.**
- Si para un algoritmo sabemos que $T_{peor} \in O(g)$, entonces se puede asegurar que **en todos los casos** el tiempo ser√° como mucho proporcional a la cota.
    
    ![Teo%203%20Algo%202%20d2eccf49e81d4599ad0ae45384cc1335/Untitled.png](Teo%203%20Algo%202%20d2eccf49e81d4599ad0ae45384cc1335/Untitled.png)
    
    ¬øC√≥mo encontramos esos valores de $n_0$ y $k$?
    
    $$
    100n^2 + 300n ‚â§ kn^2 \\
    
    $$
    
    $$
    \frac{100n^2}{n^2} + \frac{300n}{n^2} ‚â§ \frac{kn^2}{n^2} \\ 
    
    $$
    
    $$
    100 + \frac{300}{n} ‚â§ k
    $$
    
    Entonces podemos elegir, por ejemplo, $k = 400$ y $n_0 = 1$ y se cumple
    

Funciones de complejidad temporal:

- Complejidad constante $O(1)$
- Complejidad logar√≠tmica $O(log(n))$
- Complejidad lineal $O(n)$
- Complejidad nlogn $O(nlog(n))$
- Complejidad cuadr√°tica $O(n^2)$
- Complejidad c√∫bica $O(n^3)$
- Complejidad polin√≥mica $O(n^k)$
- Complejidad exponencial $O(2^n)$

**Cota Inferior - Notaci√≥n $\Omega$**

- Sirve para representar la cota inferior del tiempo de ejecuci√≥n de un algoritmo.

<aside>
üö® No confundir con el an√°lisis del mejor caso.

</aside>

![Teo%203%20Algo%202%20d2eccf49e81d4599ad0ae45384cc1335/Untitled%201.png](Teo%203%20Algo%202%20d2eccf49e81d4599ad0ae45384cc1335/Untitled%201.png)

Por ejemplo:  $100n^2 + 200n + 40 \in \Omega(n^2)$ y  $100n^2 + 200n + 40 \in \Omega(n)$, porque esa funci√≥n esta acotada **inferiormente** por $n$ y $n^2$.

**Orden exacto - Notaci√≥n $\Theta$**

- Cota **por arriba** y **por abajo**

![Teo%203%20Algo%202%20d2eccf49e81d4599ad0ae45384cc1335/Untitled%202.png](Teo%203%20Algo%202%20d2eccf49e81d4599ad0ae45384cc1335/Untitled%202.png)

Ejemplo: $100n^2 + 300n + 1000 \in \Theta(n^2)$. Podemos probarlo:

Las cotas asint√≥ticas son suficientes para decidir el mejor algoritmo, no hay que preocuparnos tanto por las constantes.