---
layout: page
title: Te√≥rica 5
permalink: /materias/orga2/teo5/
---

# Teo 5 - Resumen.

La CPU es una m√°quina de ejecuci√≥n. 

1. B√∫squeda de instrucci√≥n - Opcode Fetch 
2. Decodificaci√≥n de la instrucci√≥n - Decode
3. B√∫squeda de operandos - Operand Fetch
4. Ejecuci√≥n - Execute
5. Resultado - Write Back

Antes, todas estas etapas se hac√≠an secuencialmente. Los procesadores asignaban un ciclo de clock a cada una y toda la CPU estaba dedicada a esa tarea.

Se empez√≥ a paralelizar el proceso: 

### Instruction Level Paralelism (ILP).

- Requiere muy poco HW adicional.
- Se logra si todos los bloques funcionales trabajan en paralelo, cada uno en una instrucci√≥n diferente.
- Cada parte se denomina **stage (etapa).**

‚Äî Dibujito situaci√≥n ideal ‚Äî

La idea es que los modelos reales se aproximen lo m√°ximo posible a este.

Una estrategia es el deep pipeline, que pasa de 5 etapas a 8. ¬øQu√© es lo que cambia cuando agreg√°s m√°s etapas?

### Eficiencia de un Pipeline

TPI = Time Per Instruction

TPI = Tiempo por instrucci√≥n en la CPU ‚Äúno pipeline‚Äù / cantidad de etapas

Pareciera que cuantas m√°s etapas agregamos, el tiempo de instrucci√≥n baja. Pero en la pr√°ctica existen overheads introducidos por el pipeline que suman peque√±as demoras a cada ejecuci√≥n.

<aside>
üí° El pipeline no reduce el tiempo de ejecuci√≥n de cada instrucci√≥n,  incrementa el n√∫mero de instrucciones completadas por unidad de tiempo.

</aside>

## Obst√°culos del pipeline

Hay obst√°culos que conspiran contra la eficiencia de un pipeline. Se pueden agrupar en 3 categor√≠as:

- Obst√°culos estructurales
- Obst√°culos de datos
- Obst√°culos de control

Al efecto ocasionado por un obst√°culo se lo llama **pipeline stall.** Esto sucede cuando un obst√°culo no se puede esquivar y degrada la performance del procesador respecto del comportamiento ideal.

### Obst√°culos estructurales

Se pueden dar por varias razones:

- Una etapa no est√° lo sufucientemente ‚Äúachicada‚Äù, lo que hace que para completarse requiera de m√°s de un ciclo de clock.
- Dos instrucciones que utilizan una etapa est√°n m√°s pr√≥ximas en el tiempo que el tiempo que se necesita para procesar esa etapa. Hay un conflicto de recursos porque es como si se juntaran 2 instrucciones en la misma etapa y una tendr√° que detenerse y aumentar√° la cantidad de ciclos por instrucci√≥n.

Un ejemplo es cuando un procesador quiere ir a memoria a buscar una instrucci√≥n pero en esa misma etapa se quiere ir a memoria para buscar operandos. Entonces, cuando se intercalen, uno de estos dos fetchs va a tener que detenerse. 

Un criterio posible es darle preferencia a la instrucci√≥n de la funci√≥n que ya se estaba ejecutando, o sea que se haga el fetch de datos mientras el de instrucci√≥n espera. Esto provoca que las siguientes etapas esperen 1 ciclo m√°s de clock.

‚Äî Dibujito Obst√°culos Estructurales ‚Äî

Posibles soluciones:

En cualquiera de las soluciones ser√≠a necesario agregar HW.

- Dividir la cach√© L1 en cach√© de datos y cach√© de instrucciones.
- Emplear buffers de instrucciones implementadas como colas FIFO.
- Ensanchar los buffers m√°s all√° del tama√±o de palabra y poder leer m√°s cosas en cada ciclo de clock.

### Obst√°culos de datos

Se producen cuando una instrucci√≥n requiere un dato antes de que est√© disponible: 

```wasm
1. dadd r1, r2, r3 "r1 = r2 + r3"
2. dsub r4, r1, r5 "r4 = r1 - r5"
3. and r6, r1, r7
4. or r8, r1, r9
5. xor r10, r1, r11

"Es posible que estemos usando r1 en el resto de las operaciones sin siquiera 
haberle asignado la suma en la operaci√≥n 1."
```

Para poder ejecutarse la segunda instrucci√≥n tiene que terminar de ejecutarse la primera, por lo que no vamos a poder hacer el fetch de los operandos de la instrucci√≥n 2 (fetchear r1) hasta que la instrucci√≥n 1. no devuelva su resultado.

‚Äî dibujito obst√°culo de datos ‚Äî

Una posible soluci√≥n es hacer **forwarding.** Como en la etapa 4 ya conocemos el resultado, en vez de devolverlo (etapa 5) podemos pas√°rselo directo a la etapa 3 de la siguiente instrucci√≥n y hacer esas 2 etapas a la vez.

‚Äî dibujito forwarding ‚Äî

### Obst√°culos de control

La peor situaci√≥n en p√©rdida de performance, es un branch (una discontinuidad en el flujo de ejecuci√≥n). El branch hace que todo lo que se estaba pre-procesando deba descartarse y que el pipeline se vac√≠e. A este efecto se lo conoce como **branch penalty**. 

El principal inconveniente se tiene cuando el salto es condicional, ya que es necesario determinar si la condici√≥n es true (branch taken) o false (branch untaken).

¬øCu√°ndo se puede determinar si un salto es taken o no?

- Si es un salto condicional, en la **fase de ejecuci√≥n**.
- Si es un salto incondicional o llamada a subrutina con direccionamiento indirecto, en la **fase de b√∫squeda de operando**.
- Si es un salto incondicional o llamada a subrutina con direccionamiento directo, en la **fase de decode**.

El forwarding puede ayudar a disminuir el efecto de estos obst√°culos, pero no es √≥ptima. Hay que recurrir a an√°lisis mejores, con predicci√≥n de saltos y an√°lisis del comportamiento de los algoritmos.

## Unidades de predicci√≥n de saltos

Cuanto m√°s profundo es un pipeline (m√°s etapas tiene), m√°s grande es la penalizaci√≥n de un branch. Luego, el tiempo que demora un pipeline en recuperarse es proporcional a su cantidad de etapas.

Por eso, es **crucial** poder **predecir los saltos**, para minimizar las penalizaciones. (¬øPara que el agujero no sea tan grande y pueda empezar a fetchear antes?)

### Predicted-non-taken

El procesador asume, por default, que el salto nunca se toma. Esto funciona especialmente cuando el salto es ‚Äúhacia adelante‚Äù. 

```wasm
instrucci√≥n branch
instrucciones sucesoras secuenciales
instrucci√≥n destino de branch taken
```

### Predicted-taken

El procesador asume que el salto se toma siempre. Funciona bien en los ciclos, porque sabemos que en general se hacen muchas veces. S√≥lo falla en la √∫ltima iteraci√≥n, cuando la condici√≥n del ciclo expira.

```wasm
instrucci√≥n destino
grupo de instrucciones
instrucci√≥n branch
```

### Delayed branch y Loop Unrolling (desarrollar)

La instrucci√≥n sucesora se ejecuta siempre, independientemente del resultado del branch.

```wasm
instrucci√≥n branch
instrucci√≥n sucesora
instrucci√≥n destino branch taken
```

## Predicci√≥n de saltos din√°mica

Todos los m√©todos hasta ac√° depend√≠an exclusivamente del compilador. Ahora veremos qu√© pasa cuando el procesador es el que analiza y toma decisiones. Ingresamos al universo de la predicci√≥n din√°mica.

### Branch Prediction Buffer

Es una tabla simple indexada por la direcci√≥n de memoria de la instrucci√≥n de salto y un bit que indica simplemente el resultado reciente del salto (taken o untaken).

‚ÄúSi la √∫ltima vez no lo tom√≥, no lo tomo‚Äù. No da seguridad de nada, es una predicci√≥n basada en el √∫ltimo salto. Si se equivoca, cambia el bit del salto para la pr√≥xima predicci√≥n.

Se crea tambi√©n la predicci√≥n de 2 bits, para evitar el caso en el que hay 2 predicciones fallidas seguidas.

‚Äî dibujito predicci√≥n 2 bits ‚Äî 

Se implementa en la etapa de fetch como un peque√±o cach√© de direcciones. 

Otra forma de implementaci√≥n es .... terminar.

### Branch Target Buffer

Es un cach√© de instrucciones de salto que contiene, en cada entrada, el par <direcci√≥n de la instrucci√≥n de salto, direcci√≥n del target resuelta la √∫ltiuma vez>. Se accede mediante el valor completo del program counter.

Si no se encuentra el valor en el BTB, se asume taken. Si el resultado es taken, se agrega el valor al BTB. Si es non taken, se acepta el delay en el pipeline y no se almacena nada en el BTB.

Si se encuentra el valor, se aplica el campo de direcci√≥n target almacenado. Si el resultado es taken, no hay penalidad y no se guarda ning√∫n nuevo valor. Si es non taken, guarda el nuevo valor en el BTB luego de la penalidad correspondiente en el pipeline.

# Procesadores Superscalar

El objetivo es ejecutar m√°s de una instrucci√≥n por ciclo de reloj.

¬øC√≥mo? Con m√°s paralelismo.

‚Äî dibujo superscalar de 2 v√≠as ‚Äî

Contras:

- M√°s paralelismo ‚Üí m√°s obst√°culos.
- Los obst√°culos estructurales quedan m√°s expuestos.
- Recordando el problema del acceso simult√°neo a memoria, ahora, adem√°s de tener que lidiar con otras etapas del mismo pipeline, hay que lidiar con las mismas etapas del otro pipeline.
- Se podr√≠a ejecutar en 2 ALUs diferentes, pero si una instrucci√≥n depende de la otra no.
- Una falla en branch es letal. Borra TODO.

# Scheduling Din√°mico

Hasta ahora venimos estudiando pipelines con scheduling de instrucciones est√°tico, en los que se busca una instrucci√≥n y se la env√≠a a la unidad de ejecuci√≥n (**dispatch**).

En caso de que una instrucci√≥n se ‚Äúchoque‚Äù con otra en el pipeline, el env√≠o es demorado (**pipeline stall**).

En el caso de los superscalar, el estudio de dependencias/choques se debe extender a instrucciones en los diferentes pipelines. Esto vuelve insuficiente el m√©todo forwarding. 

**Idea del Scheduling Din√°mico:**

Si una instrucci√≥n $j$ depende de una instrucci√≥n $i$, que para completarse requiere de varios ciclos de clock adicionales debido a obst√°culos, la instrucci√≥n $j$ y todas las instrucciones que la siguen no pueden ser ejecutadas. (Pipeline stall).

Esta obstrucci√≥n del pipeline deja en estado IDLE a todas las unidades funcionales que componen la unidad de ejecuci√≥n del pipeline.

```wasm
divd F0, F2, F4
addd F10, F0, F8
subd F8, F12, F14 
```

La ejecuci√≥n del `divd` obstruye la ejecuci√≥n del `addd` porque tiene que esperar a que se guarde el resultado en F0.

La instrucci√≥n `subd`, a pesar de no guardar dependencia con las instrucciones previas, queda esperando que se complete la instrucci√≥n responsable del ‚Äúatasco‚Äù.

---

### Ejecuci√≥n Fuera de Orden

la ejecuci ÃÅon en orden no siempre ofrece un rendimiento  ÃÅoptimo debido a las dependencias que pueden existir entre las distintas instrucciones que un compilador no puede resolver.

Consiste en enviar instrucciones a √©jecuci√≥n, independientemente del orden en el que est√°n, pero manteniendo un orden l√≥gico determinado por las dependencias entre las distintas instrucciones. 

¬øCon qu√© criterio? La decisi√≥n se toma una vez decodificada la instrucci√≥n, ya que ah√≠ se sabe si hay un atasco que provoque un pipeline stall en instrucciones siguientes.

Cada vez que intentemos hacer esto hay que tener en cuenta los riesgos: 

- divd demora varios ciclos y atasca a addd.
- es posible enviar subd.
- hay riesgo de que se escriba en F8 en la instrucci√≥n 3, cuando F8 es operando de la instrucci√≥n 2.
- tambi√©n puede pasar que la instrucci√≥n 4 escriba en el mismo destino que la 2.

‚Äî dibujo ejecuci√≥n fuera de orden ‚Äî

Riesgos: 

- WAR (Write After Read): que se escriba en un registro que es operando de una instrucci√≥n anterior.
- WAW (Write After Write): que se escriba en un registro en el que se iba a escribir en una instrucci√≥n anterior.
- RAW (Read After Write): Es cuando se lee un operando que una instrucci√≥n previa a√∫n est√° por cambiar. Esto no pasa en OOO.

Al ejecutar Fuera de Orden, el procesador puede generar lo que se denominan **excepciones imprecisas.** 

Se producen en la fase de ejecuci√≥n y se da cuando el estado del procesador no es el mismo del que ser√≠a si las instrucciones se hubiesen ejecutado en orden. Se dan por 2 posibles razones: 

1. El pipeline ejecut√≥ una o m√°s instrucciones posteriores a la que produce la excepci√≥n.
2. El pipeline no ha completado a√∫n al menos una instrucci√≥n previa a la que genera la excepci√≥n.

---

¬øC√≥mo implementar OOO?

**Scoreboarding:** evitaba los riesgos WAR y WAW en el 1964. Era muy limitada.

### Algoritmo de Tomasulo (1967)

Su inter√©s fue minimizar los riesgos de RAW e implementar *Register Renaming* en los WAR y WAW, neutraliz√°ndolos. Para eso, implement√≥ un m√©todo conocido como **Register Renaming**, usando *buffers* llamados **Reservation Stations**.

¬øQu√© necesita un procesador para implementarlo?

1. Mantener un link entre el **productor** y el **consumidor** de un dato.
2. Mantener instrucciones en espera hasta que est√©n listas para su ejecuci√≥n.
3. Las instrucciones deben saber cuando sus operandos est√°n *ready*.
4. Disparar la instrucci√≥n cuando todos los operandos est√©n *ready.*

1. Enlace entre productor y consumidor/es.
    
    ¬øC√≥mo se produce el link entre el productor del dato y sus consumidores? **Register renaming:** permite asociar un tag con cada operando, que usaremos para identificar al registro de la **Reservation Station** que contiene la instrucci√≥n que producir√° su valor. Este tag lo conseguimos en la **Register Alias Table**.
    
    ```coffeescript
    div.d F0, F2, F4
    add.d F6, F0, F8 # Riesgo WAR con F8 en sub
    s.d   F6, O(R1)
    sub.d F8, F10, F14
    mul.d F6, F10, F8 # Riesgo WAW.
    ```
    

Se hace an√°lisis del c√≥digo de manera de ‚Äúmirar m√°s adelante‚Äù de cada instrucci√≥n en busca de estos riesgos.

Se implementa mediante la Register Alias Table.

Consiste en una tabla en la que cada Registro tiene una entrada, que contiene un tag, un valor y un bit de validez.

En el tag se escribe el renombre del registro. Al prinicpio empieza con el bit de validez en 0 y en valor el valor actual.

![Untitled](teo5/Untitled.png)

### Reservation Station

Las instrucciones, para ser despachadas, tienen que esperar en el **Reservation Station**. Son aquellas instrucciones que deber√≠an estar en ejecuci√≥n pero no est√°n en *ready* porque les falta alg√∫n operando o algo as√≠.

En la reservation station vamos a tener todos los operandos de cada instrucci√≥n marcados como ready o no. En definitiva, termina siendo un gran *buffer* en el cual se colocan las instrucciones hasta que est√©n *ready*.

Cada vez que una unidad de ejecuci√≥n pone disponible un operando (o sea que termina de ejecutar una instrucci√≥n), hace broadcast y le manda su tag y su valor a todas las Reservation Stations. Todas estas van a fijarse si tienen ese tag, y en caso de que lo tengan, van a pisar el valor y marcar el operando como ready. Si un operando recibe m√∫ltiples escrituras, la Reservation Station aplica s√≥lo la √∫ltima. 

Ahora, como el bit de validez est√° en 1, la l√≥gica no va a mirar el tag sino directamente el valor.

Cuando todos los bits de validez de cada operando de la instrucci√≥n est√©n en 1, la instrucci√≥n va a estar *ready* y ser√° despachada.

- Si no hay ninguna unidad funcional disponible, la instrucci√≥n se encola y espera.
- Si la RS tiene muchos m√°s registros que la arquitectura se pueden eliminar los riesgos estudiados (WAR, WAW).

Entonces, no puede pasar que una instrucci√≥n cuya ejecuci√≥n se adelanta respecto de otra, modifique o utilice un registro de la instrucci√≥n previa y que √©sta luego use una copia incorrecta del mismo.

‚Äî dibujo FPU IBM sin y con Tomasulo ‚Äî

Tomasulo agrega 2 reservation stations (una con 3 y otra con 2 registros). Tambi√©n est√° el common data bus, que el crucial en el broadcast de los resultados porque atraviesa la salida de todas las unidades funcionales y pasa por las Reservation Stations.

**Etapas por las que pasa una instrucci√≥n en Tomasulo:**

- Fetch:
- Issue: el procesador determina a cu√°l RS tiene que despachar la in. trucci√≥n, basado en la unidad funcional que la requiere. Si no hay ninguna unidad funcional disponible, la instrucci√≥n se ***stallea*** y espera a que se vac√≠e alg√∫n espacio.
    
    Una instrucci√≥n puede ser despachada a pesar de que sus opeandos a√∫n no est√©n disponibles. Lo que va a pasar es que se va a estar monitoreando el CDB esperando a que alguna unidad funcional env√≠e el tag y el nuevo valor del operando que nos falta, una vez que haya terminado de calcularlo.
    
- Execute: una vez que todos los operandos est√°n disponibles y la unidad funcional correspondiente puede aceptar una nueva instrucci√≥n, la operaci√≥n ya puede ser ejecutada.
- Write Result: cuando el resultado est√© disponible, se env√≠a el valor junto con el tag de la RS que produjo el resultado a trav√©s del Common Data Bus, entregando el resultado a la RAT y a las Reservation Stations que lo esperaban.

<aside>
üí° Los tags en el esquema de Tomasulo (en la RAT) hacen referencia a los registros de la RS que producir√° el resultado, y el nombre original de los registros fuente son descartados cuando la instrucci√≥n se despacha a una Reservation Station.

</aside>

El uso de RS trae 2 propiedades importantes:

- La detecci√≥n de dependencias y el control de ejecuci√≥n son distribuidos, porque la informaci√≥n almacenada en las RS de cada unidad funcional determina cu√°ndo una instrucci√≥n puede ser ejecutada en esa unidad.
- Todos los resultados son broadcasteados por el CBD, que se conecta a los registros, RAT, RS y buffers, evitando tener que pasar primero por los registros para luego actualizar el resto de las unidades. De esta manera, si varias unidades funcionales est√°n esperando un operando resultado, podr√≠an ejecutar la instrucci√≥n de forma simult√°nea al momento de recibir el broadcast de ese operando. Si se tuviera un banco de registros centralizado, las unidades deber√≠an ir a ese banco a leer s√≥lo cuando los buses estuvieran disponibles (eso se hac√≠a en *scoreboarding*).

```wasm
Algoritmo de Tomasulo

if (RS tiene recursos disponibles):
	Se inserta en la RS la instrucci√≥n y los operandos renombrados <valor, tag>

else:
	stall 

for (cada instrucci√≥n en la RS):
	Mirar el tr√°fico en el Common Data Bus en busca de tags que correspondan a sus operandos.
	if (se detecta un tag):
		pisar el valor
	if (todos los operandos est√°n ready):
		marcarse como ready

if (unidad funcional disponible):
	despachar esa instruccion a esa unidad funcional

if (finalizada la ejecuci√≥n de la instrucci√≥n):
	la unidad funcional arbitra el CBD.
	Poner el valor al tag en el CBD (tag broadcast)
	if (el archivo de registros est√° conectado al CBD):
		if (tag del archivo de registro == tag broadcast):
			registro = tag broadcast.

```

---

```coffeescript
# Pipeline: Fetch-Decode-Execute-Result-Write

loa d R1, 0 (R3) #ptr
mul R6, R1, R2
add R11, R11, R6
sub R3, R3, R2
add R7, R8, R8
add R20, R8, R3

# La 1era instr. demora 12 ciclos de clock en ejecutarse.
# mul tarda 4 ciclos de clock.
# El resto demora 1 ciclo cada una.
```

El tag que le ponemos a un registro tiene que coincidir con una entrada en la Reservation Station de alguna unidad funcional. Puede haber 1 o tantas RS como unidades funcionales, pero no se pueden repetir los tags. 

### Ejecuci√≥n Especulativa - Reorder Buffer

Volvemos a *branch prediction.* A medida que aumentamos el paralelismo a nivel de instrucciones, se va complicando el control de dependencias. La predicci√≥n de saltos permite reducir los *stalls* asociados a los *branches* pero no podemos ejecutar estas instrucciones hasta que no sepamos la evaluaci√≥n del branch, ya que no se pueden deshacer esos resultados. Esto representa una gran p√©rdida de tiempo.

Es posible superar estas dependencias de control **especulando** sobre la evaluaci√≥n de los *branches.* Es una extensi√≥n de la predicci√≥n de saltos con *scheduling* din√°mico. Vamos a fetchear, despachar y ejecutar las instrucciones como si nuestras predicciones fueran correctas, pero hay que tener la capacidad de **deshacer la operaci√≥n** en caso de que la especulaci√≥n no haya sido correcta.

Vamos a permitir que las instrucciones sean ejecutadas fuera de orden, pero forzar a que se commiteen en orden, para evitar cualquier acci√≥n irreversible.

Entonces, primero se broadcastean los resultados de las instrucciones (que fueron ejecutadas de forma especulativa) y luego, una vez que sepamos la evaluaci√≥n del *branch,* se comitean los resultados.

Para implementar esto, se introduce el ***Reorder Buffer* (ROB).**

El ROB es un buffer con punteros *head* y *tail.* Cuando una instrucci√≥n es despachada, la pr√≥xima entrada del ROB, apuntada por el *tail,* es asignada a esa instrucci√≥n. El n√∫mero de esa entrada termina siendo usado como *tag* para el renaming. Luego, el puntero a *tail* es incrementado.

De esta manera, las instrucciones ejecutadas de forma especulativa se van almacenando en el ROB, hasta que esos resultados sean comitteados. As√≠, la ejecuci√≥n se mantiene fuera de orden pero la aplicaci√≥n de los resultados es en orden.

Suponiendo que tenemos varias instrucciones, de las cuales la primera no est√° lista pero la segunda y la tercera s√≠, todav√≠a no aplicamos nada. Ahora, cuando la primera instrucci√≥n se marque v√°lida, ya aplicamos las 3 y corremos la ‚Äúventana‚Äù 3 lugares para abajo.

Cuando trabajamos con ejecuci√≥n especulativa, el banco de registros no es actualizado hasta el commit de los resultados, o sea, hasta qeu tengamos la certeza de que esa instrucci√≥n es v√°lida. Mientras tanto, el ROB se encarga de mantener la √∫ltima versi√≥n de los registros. hasta que los resultados de las instrucciones anteriores sean commiteados.

Cada entrada del ROB tiene 4 campos:

- El tipo de instrucci√≥n. Indica si se trata de un branch (no tiene operando), un store (tiene como destino una dir. de memoria) o una operaci√≥n con registros.
- El campo destino. Contiene el n√∫mero de registro o direcci√≥n de memoria en donde se guardar√° el resultado.
- El campo valor. Para mantener el resultado de la instrucci√≥n, hasta el commit.
- El bit de ready. Indica si la ejecuci√≥n ya fue ejecutada, por lo que el campo valor ser√≠a v√°lido.

Tambi√©n podr√≠a haber un poison bit, que indica si la instrucci√≥n ejecutada gener√≥ una excepci√≥n. Esta excepci√≥n podr√≠a ser innecesaria (depende del branch).

**Etapas de una instrucci√≥n usando ROB:**

- **Issue (env√≠o)**: se obtiene la primera instrucci√≥n de la cola de preb√∫squeda. La instrucci√≥n es despachada a una RS de la unidad funcional correspondiente a la instrucci√≥n (si hay espacio) y si tenemos una entrada disponible en el ROB.
    
    Si no hay un RS disponible o no hay un slot libre en el ROB, hay un obst√°culo estructural, por lo cual la instrucci√≥n queda bloqueada (stall).
    
    Cuando se env√≠a la instrucci√≥n, se hace junto con los datos correspondientes a sus operandos, si estos est√°n disponibles en sus registros.
    
    Luego, se actualizan las estructuras internas con la informaci√≥n pertinente.
    
- **Ejecuci√≥n:** si uno o m√°s operandos no est√°n disponibles, se ve el CBD hasta que lleguen los resultados. De esta manera, se resuelven los RAW. Cuando est√°n disponibles todos, se ejecutan.
- **Write Result**: cuando el resultado est√° disponible, se escribe en el CDB con el tag que se obtuvo del ROB para broadcastear el resultado. Esto se escribe en el ROB, en los RS y en el registro correspondiente. Se setea el bit de validez para ese operando.
- **Commit:** luego de esto el resultado s√≥lo estar√° en el operando destino.
    
    Pueden pasar 3 cosas distintas en esta etapa, dependiendo del tipo de instrucci√≥n (branch, store, ‚Äúnormal‚Äù).
    
    - Si es un branch con predicci√≥n incorrecta, flushea las entradas del ROB y recomienza a partir de la instrucci√≥n sucesora correcta del branch.
    - Para cualquier instrucci√≥n que finaliza correctamente (excepto memory stores) y para los branches con predicci√≥n correcta, se copia el valor del ROB en el operando destino.
    - Si la operaci√≥n es un memory store es similar solo que se escribe en una direcci√≥n de memoria.